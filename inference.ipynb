{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/sohom/cuda/lib/python3.11/site-packages (2.1.0)\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.16.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: transformers in /Users/sohom/cuda/lib/python3.11/site-packages (4.34.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/sohom/cuda/lib/python3.11/site-packages (0.1.99)\n",
      "Requirement already satisfied: pandas in /Users/sohom/cuda/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: tqdm in /Users/sohom/cuda/lib/python3.11/site-packages (4.66.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /Users/sohom/cuda/lib/python3.11/site-packages (from torch) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/sohom/cuda/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/sohom/cuda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/sohom/cuda/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/sohom/cuda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/sohom/cuda/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/sohom/cuda/lib/python3.11/site-packages (from torchtext) (2.31.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.1.2-cp311-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy in /Users/sohom/cuda/lib/python3.11/site-packages (from torchtext) (1.25.2)\n",
      "Collecting torchdata==0.7.1 (from torchtext)\n",
      "  Downloading torchdata-0.7.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in /Users/sohom/cuda/lib/python3.11/site-packages (from torchdata==0.7.1->torchtext) (1.26.18)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/sohom/cuda/lib/python3.11/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sohom/cuda/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sohom/cuda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sohom/cuda/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/sohom/cuda/lib/python3.11/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/sohom/cuda/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sohom/cuda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sohom/cuda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sohom/cuda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Downloading pyarrow-14.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp in /Users/sohom/cuda/lib/python3.11/site-packages (from datasets) (3.8.6)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Using cached huggingface_hub-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sohom/cuda/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/sohom/cuda/lib/python3.11/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sohom/cuda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/sohom/cuda/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sohom/cuda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sohom/cuda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sohom/cuda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sohom/cuda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sohom/cuda/lib/python3.11/site-packages (from requests->torchtext) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sohom/cuda/lib/python3.11/site-packages (from requests->torchtext) (2023.7.22)\n",
      "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.14.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading datasets-2.14.7-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sohom/cuda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/sohom/cuda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torchtext-0.16.2-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torch-2.1.2-cp311-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchdata-0.7.1-cp311-cp311-macosx_11_0_arm64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-14.0.2-cp311-cp311-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, dill, torch, multiprocess, torchdata, torchtext, datasets\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0\n",
      "    Uninstalling torch-2.1.0:\n",
      "      Successfully uninstalled torch-2.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.14.7 dill-0.3.7 multiprocess-0.70.15 pyarrow-14.0.2 pyarrow-hotfix-0.6 torch-2.1.2 torchdata-0.7.1 torchtext-0.16.2 xxhash-3.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchtext transformers sentencepiece pandas tqdm datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "import ast\n",
    "import datasets\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb20ebaaf154c02a621b7f9192ca9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/381 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b9ecfec18e499a9de5e9a9dd76c89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31399ffe90b41089812c1b5069829d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/107k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c501e7d8ab04456bf00f1e9660f8aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520d4f6614064fba87e85145a8ef3c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data set from huggingface\n",
    "data_sample = load_dataset(\"QuyenAnhDE/Diseases_Symptoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Code', 'Name', 'Symptoms', 'Treatments'],\n",
       "        num_rows: 400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a pandas dataframe\n",
    "updated_data = [{'Name': item['Name'], 'Symptoms': item['Symptoms']} for item in data_sample['train']]\n",
    "df = pd.DataFrame(updated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panic disorder</td>\n",
       "      <td>Palpitations, Sweating, Trembling, Shortness o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vocal cord polyp</td>\n",
       "      <td>Hoarseness, Vocal Changes, Vocal Fatigue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turner syndrome</td>\n",
       "      <td>Short stature, Gonadal dysgenesis, Webbed neck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cryptorchidism</td>\n",
       "      <td>Absence or undescended testicle(s), empty scro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethylene glycol poisoning-1</td>\n",
       "      <td>Nausea, vomiting, abdominal pain, General mala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  \\\n",
       "0               Panic disorder   \n",
       "1             Vocal cord polyp   \n",
       "2              Turner syndrome   \n",
       "3               Cryptorchidism   \n",
       "4  Ethylene glycol poisoning-1   \n",
       "\n",
       "                                            Symptoms  \n",
       "0  Palpitations, Sweating, Trembling, Shortness o...  \n",
       "1           Hoarseness, Vocal Changes, Vocal Fatigue  \n",
       "2  Short stature, Gonadal dysgenesis, Webbed neck...  \n",
       "3  Absence or undescended testicle(s), empty scro...  \n",
       "4  Nausea, vomiting, abdominal pain, General mala...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panic disorder</td>\n",
       "      <td>Palpitations, Sweating, Trembling, Shortness o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vocal cord polyp</td>\n",
       "      <td>Hoarseness, Vocal Changes, Vocal Fatigue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turner syndrome</td>\n",
       "      <td>Short stature, Gonadal dysgenesis, Webbed neck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cryptorchidism</td>\n",
       "      <td>Absence or undescended testicle(s), empty scro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethylene glycol poisoning-1</td>\n",
       "      <td>Nausea, vomiting, abdominal pain, General mala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  \\\n",
       "0               Panic disorder   \n",
       "1             Vocal cord polyp   \n",
       "2              Turner syndrome   \n",
       "3               Cryptorchidism   \n",
       "4  Ethylene glycol poisoning-1   \n",
       "\n",
       "                                            Symptoms  \n",
       "0  Palpitations, Sweating, Trembling, Shortness o...  \n",
       "1           Hoarseness, Vocal Changes, Vocal Fatigue  \n",
       "2  Short stature, Gonadal dysgenesis, Webbed neck...  \n",
       "3  Absence or undescended testicle(s), empty scro...  \n",
       "4  Nausea, vomiting, abdominal pain, General mala...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just extract the Symptoms\n",
    "df['Symptoms'] = df['Symptoms'].apply(lambda x: ', '.join(x.split(', ')))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have an NVIDIA GPU attached, use 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    # If Apple Silicon, set to 'mps' - otherwise 'cpu' (not advised)\n",
    "    try:\n",
    "        device = torch.device('mps')\n",
    "    except Exception:\n",
    "        device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008069a641ec42968fcf2b999a3bca49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053579eac4db4bc3967108583a656ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00ef789e3314706952e5a281d6b435e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180ce3e6255a4a0eab5a164b0baea731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e8fb33603842869456b797c202e453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e91e41224c1450d9f840a071fc48eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The tokenizer turns texts to numbers (and vice-versa)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "\n",
    "# The transformer\n",
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Symptoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>392</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sciatica</td>\n",
       "      <td>Swelling, pain, dry mouth, bad taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name                              Symptoms\n",
       "count        400                                   400\n",
       "unique       392                                   395\n",
       "top     Sciatica  Swelling, pain, dry mouth, bad taste\n",
       "freq           3                                     3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Prep\n",
    "class LanguageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    An extension of the Dataset object to:\n",
    "      - Make training loop cleaner\n",
    "      - Make ingestion easier from pandas df's\n",
    "    \"\"\"\n",
    "    def __init__(self, df, tokenizer):\n",
    "        self.labels = df.columns\n",
    "        self.data = df.to_dict(orient='records')\n",
    "        self.tokenizer = tokenizer\n",
    "        x = self.fittest_max_length(df)  # Fix here\n",
    "        self.max_length = x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx][self.labels[0]]\n",
    "        y = self.data[idx][self.labels[1]]\n",
    "        text = f\"{x} | {y}\"\n",
    "        tokens = self.tokenizer.encode_plus(text, return_tensors='pt', max_length=128, padding='max_length', truncation=True)\n",
    "        return tokens\n",
    "\n",
    "    def fittest_max_length(self, df):  # Fix here\n",
    "        \"\"\"\n",
    "        Smallest power of two larger than the longest term in the data set.\n",
    "        Important to set up max length to speed training time.\n",
    "        \"\"\"\n",
    "        max_length = max(len(max(df[self.labels[0]], key=len)), len(max(df[self.labels[1]], key=len)))\n",
    "        x = 2\n",
    "        while x < max_length: x = x * 2\n",
    "        return x\n",
    "\n",
    "# Cast the Huggingface data set as a LanguageDataset we defined above\n",
    "data_sample = LanguageDataset(df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LanguageDataset at 0x28c105b90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, valid\n",
    "train_size = int(0.8 * len(data_sample))\n",
    "valid_size = len(data_sample) - train_size\n",
    "train_data, valid_data = random_split(data_sample, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the iterators\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = BATCH_SIZE\n",
    "model_name = 'distilgpt2'\n",
    "gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the learning rate and loss function\n",
    "## CrossEntropyLoss measures how close answers to the truth.\n",
    "## More punishing for high confidence wrong answers\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = tokenizer.pad_token_id)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init a results dataframe\n",
    "results = pd.DataFrame(columns=['epoch', 'transformer', 'batch_size', 'gpu',\n",
    "                                'training_loss', 'validation_loss', 'epoch_duration_sec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 40/40 [01:09<00:00,  1.74s/it, Training Loss=0.66] \n",
      "Validation Epoch 1/10: 100%|██████████| 10/10 [00:17<00:00,  1.70s/it, Validation Loss=0.879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Validation Loss: 0.6696192622184753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/10 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 40/40 [00:38<00:00,  1.04it/s, Training Loss=0.572]\n",
      "Validation Epoch 2/10: 100%|██████████| 10/10 [00:02<00:00,  4.28it/s, Validation Loss=0.883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Validation Loss: 0.6555699706077576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/10 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 40/40 [00:38<00:00,  1.05it/s, Training Loss=0.29] \n",
      "Validation Epoch 3/10: 100%|██████████| 10/10 [00:02<00:00,  4.20it/s, Validation Loss=0.874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Validation Loss: 0.6493533253669739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/10 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 40/40 [00:35<00:00,  1.12it/s, Training Loss=0.259]\n",
      "Validation Epoch 4/10: 100%|██████████| 10/10 [00:02<00:00,  4.37it/s, Validation Loss=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Validation Loss: 0.6990770101547241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/10 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 40/40 [00:38<00:00,  1.03it/s, Training Loss=0.265]\n",
      "Validation Epoch 5/10: 100%|██████████| 10/10 [00:02<00:00,  3.66it/s, Validation Loss=0.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Validation Loss: 0.7238613367080688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/10 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 40/40 [00:38<00:00,  1.05it/s, Training Loss=0.191]\n",
      "Validation Epoch 6/10: 100%|██████████| 10/10 [00:02<00:00,  4.41it/s, Validation Loss=0.993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Validation Loss: 0.7766691446304321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/10 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 40/40 [00:34<00:00,  1.17it/s, Training Loss=0.195]\n",
      "Validation Epoch 7/10: 100%|██████████| 10/10 [00:02<00:00,  4.51it/s, Validation Loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Validation Loss: 0.8183935880661011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/10 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 40/40 [00:34<00:00,  1.17it/s, Training Loss=0.145] \n",
      "Validation Epoch 8/10: 100%|██████████| 10/10 [00:02<00:00,  4.49it/s, Validation Loss=1.16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Validation Loss: 0.8820027112960815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/10 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 40/40 [00:34<00:00,  1.18it/s, Training Loss=0.129] \n",
      "Validation Epoch 9/10: 100%|██████████| 10/10 [00:02<00:00,  4.52it/s, Validation Loss=1.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Validation Loss: 0.8839861750602722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/10 Batch Size: 8, Transformer: distilgpt2: 100%|██████████| 40/40 [08:10<00:00, 12.26s/it, Training Loss=0.076] \n",
      "Validation Epoch 10/10: 100%|██████████| 10/10 [00:02<00:00,  4.29it/s, Validation Loss=1.2] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Validation Loss: 0.9331303834915161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The training loop\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  # Start the timer for the epoch\n",
    "\n",
    "    # Training\n",
    "    ## This line tells the model we're in 'learning mode'\n",
    "    model.train()\n",
    "    epoch_training_loss = 0\n",
    "    train_iterator = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs} Batch Size: {batch_size}, Transformer: {model_name}\")\n",
    "    for batch in train_iterator:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "        targets = inputs.clone()\n",
    "        outputs = model(input_ids=inputs, labels=targets)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_iterator.set_postfix({'Training Loss': loss.item()})\n",
    "        epoch_training_loss += loss.item()\n",
    "    avg_epoch_training_loss = epoch_training_loss / len(train_iterator)\n",
    "\n",
    "    # Validation\n",
    "    ## This line below tells the model to 'stop learning'\n",
    "    model.eval()\n",
    "    epoch_validation_loss = 0\n",
    "    total_loss = 0\n",
    "    valid_iterator = tqdm(valid_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\")\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_iterator:\n",
    "            inputs = batch['input_ids'].squeeze(1).to(device)\n",
    "            targets = inputs.clone()\n",
    "            outputs = model(input_ids=inputs, labels=targets)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss\n",
    "            valid_iterator.set_postfix({'Validation Loss': loss.item()})\n",
    "            epoch_validation_loss += loss.item()\n",
    "\n",
    "    avg_epoch_validation_loss = epoch_validation_loss / len(valid_loader)\n",
    "\n",
    "    end_time = time.time()  # End the timer for the epoch\n",
    "    epoch_duration_sec = end_time - start_time  # Calculate the duration in seconds\n",
    "\n",
    "    new_row = {'transformer': model_name,\n",
    "               'batch_size': batch_size,\n",
    "               'gpu': gpu,\n",
    "               'epoch': epoch+1,\n",
    "               'training_loss': avg_epoch_training_loss,\n",
    "               'validation_loss': avg_epoch_validation_loss,\n",
    "               'epoch_duration_sec': epoch_duration_sec}  # Add epoch_duration to the dataframe\n",
    "\n",
    "    results.loc[len(results)] = new_row\n",
    "    print(f\"Epoch: {epoch+1}, Validation Loss: {total_loss/len(valid_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kidney Failure | Decreased urine output, fluid retention, fatigue\n"
     ]
    }
   ],
   "source": [
    "input_str = \"Kidney Failure\"\n",
    "input_ids = tokenizer.encode(input_str, return_tensors='pt').to(device)\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=20,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    top_k=8,\n",
    "    top_p=0.95,\n",
    "    temperature=0.5,\n",
    "    repetition_penalty=1.2\n",
    ")\n",
    "\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(decoded_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
